{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchaudio.functional as F\n",
    "from util.patch_embed import PatchEmbed_org\n",
    "from model import PositionalEncoding\n",
    "from models_mae import MaskedAutoencoder\n",
    "from datasets import load_dataset, Audio\n",
    "from util import misc\n",
    "from model.vit import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = int(sample_rate * 0.025)  # 25ms\n",
    "hop_length = int(sample_rate * 0.01)  # 10ms\n",
    "transform = MelSpectrogram(\n",
    "    sample_rate=args.sample_rate,\n",
    "    win_length=win_length,\n",
    "    hop_length=hop_length,\n",
    "    n_fft=win_length,\n",
    "    n_mels=128,\n",
    "    window_fn=torch.hamming_window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aad45f4d8084e9c9f8a438380ac7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/1739 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f046554174b84e99832509757dc2f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"agkphysics/AudioSet\", \"unbalanced\", trust_remote_code=True)[\"train\"].cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "loader = DataLoader(ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': ['---1_cCGK4M'],\n",
       " 'audio': {'path': ['audio/unbal_train/---1_cCGK4M.flac'],\n",
       "  'array': tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.1237, -0.0929,  0.0805]],\n",
       "         dtype=torch.float64),\n",
       "  'sampling_rate': tensor([16000])},\n",
       " 'labels': [('/m/01g50p',),\n",
       "  ('/m/0284vy3',),\n",
       "  ('/m/06d_3',),\n",
       "  ('/m/07jdr',),\n",
       "  ('/m/07rwm0c',)],\n",
       " 'human_labels': [('Railroad car, train wagon',),\n",
       "  ('Train horn',),\n",
       "  ('Rail transport',),\n",
       "  ('Train',),\n",
       "  ('Clickety-clack',)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': '--6CkUtkLUI',\n",
       " 'audio': {'path': 'audio/unbal_train/--6CkUtkLUI.flac',\n",
       "  'array': array([-0.01472282, -0.0122354 , -0.01414704, ...,  0.05027008,\n",
       "          0.07025385,  0.08694172]),\n",
       "  'sampling_rate': 48000},\n",
       " 'labels': ['/m/09x0r'],\n",
       " 'human_labels': ['Speech']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    wavs = torch.tensor([])\n",
    "    for data in batch:\n",
    "        wav = torch.from_numpy(data['audio']['array']).reshape(1, -1).float()\n",
    "\n",
    "        # resample to 16000\n",
    "        wav = F.resample(wav, data['audio']['sampling_rate'], 16000)\n",
    "        \n",
    "        # pad small white noise to 160000, which is 10 seconds\n",
    "        N, L = wav.shape\n",
    "        if L < 16000*10:\n",
    "            append_len = 16000*10 - L \n",
    "            wav = torch.cat([wav, torch.randn(1, append_len)*0.001], dim=-1)\n",
    "        elif L > 16000*10:\n",
    "            wav = wav[:, :16000*10]\n",
    "            \n",
    "        wavs = torch.cat([wavs, wav], dim=0)\n",
    "            \n",
    "    return wavs.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.DistributedSampler(\n",
    "            ds, num_replicas=1, rank=0, shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=512,\n",
    "        sampler=sampler_train,\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.2006e-02, -1.2006e-02,  4.7385e-02,  ..., -1.3327e-03,\n",
      "          -2.0157e-04,  2.5619e-04]],\n",
      "\n",
      "        [[-5.8748e-02, -9.1860e-02, -6.6118e-02,  ...,  1.4414e-03,\n",
      "           1.0130e-03,  5.5223e-04]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -9.2150e-04,\n",
      "          -1.6165e-05,  2.5540e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3873e-01,  3.1841e-01,  4.7802e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.6606e-02,  2.8510e-02,  2.7521e-02,  ..., -8.5156e-04,\n",
      "          -2.2067e-03, -2.4989e-03]],\n",
      "\n",
      "        [[ 3.2547e-03,  6.7471e-03,  2.8442e-03,  ..., -3.5225e-03,\n",
      "          -1.6203e-03, -4.9664e-03]]])\n",
      "tensor([[[ 4.5977e-01,  7.3646e-01,  6.4494e-01,  ..., -7.0729e-01,\n",
      "          -7.4497e-01, -5.0585e-01]],\n",
      "\n",
      "        [[ 6.6824e-03, -2.1251e-02, -4.0596e-02,  ..., -2.3610e-02,\n",
      "          -8.8257e-03,  3.1037e-02]],\n",
      "\n",
      "        [[-3.0426e-02, -4.8213e-02, -3.9586e-02,  ..., -2.1600e-04,\n",
      "          -3.9023e-03, -7.3961e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3373e-01, -2.2340e-01, -1.8287e-01,  ...,  1.6910e-01,\n",
      "           1.8646e-01,  2.5602e-01]],\n",
      "\n",
      "        [[-3.7161e-03, -4.9704e-03, -5.2066e-03,  ...,  8.7510e-03,\n",
      "           9.3670e-04,  1.4378e-03]],\n",
      "\n",
      "        [[ 3.1986e-03,  6.3204e-03,  6.9188e-03,  ..., -2.8972e-02,\n",
      "          -3.0619e-02, -3.2536e-02]]])\n",
      "tensor([[[-5.2720e-02,  1.2097e-02,  3.0581e-02,  ...,  2.5705e-04,\n",
      "           6.9946e-04, -6.0057e-04]],\n",
      "\n",
      "        [[-8.8188e-03, -2.4349e-02, -2.3540e-02,  ..., -1.9291e-02,\n",
      "          -2.9229e-02, -2.6525e-02]],\n",
      "\n",
      "        [[ 1.5430e-03, -7.6864e-02, -6.9822e-02,  ..., -1.4771e-01,\n",
      "          -1.0216e-01, -1.8962e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6700e-01, -2.6503e-01, -2.4924e-01,  ...,  2.6320e-02,\n",
      "           4.6143e-02,  7.4935e-02]],\n",
      "\n",
      "        [[ 6.0126e-04,  8.0506e-04,  3.8910e-04,  ..., -1.0571e-02,\n",
      "           2.9960e-03,  2.0096e-02]],\n",
      "\n",
      "        [[ 4.1051e-03,  1.1182e-02,  2.1166e-02,  ...,  4.3569e-03,\n",
      "          -2.4057e-02, -5.1814e-02]]])\n",
      "tensor([[[-8.9469e-04, -2.7013e-03, -4.3360e-03,  ...,  5.1055e-03,\n",
      "           4.2144e-03,  3.8460e-03]],\n",
      "\n",
      "        [[-2.0364e-01, -3.2779e-01, -2.7045e-01,  ...,  1.6262e-01,\n",
      "           8.5680e-02, -1.0087e-01]],\n",
      "\n",
      "        [[-5.4370e-03,  1.4019e-03,  7.1703e-04,  ...,  6.8651e-02,\n",
      "          -5.8206e-02, -5.6827e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.2679e-04, -8.9528e-04,  2.0722e-03,  ...,  1.0263e-02,\n",
      "           1.3116e-02,  2.0539e-02]],\n",
      "\n",
      "        [[ 1.1006e-03,  6.7757e-03,  1.7751e-02,  ...,  1.6209e-02,\n",
      "           1.6002e-02,  2.6780e-02]],\n",
      "\n",
      "        [[ 6.7046e-02,  1.0737e-01,  9.1531e-02,  ...,  2.9697e-04,\n",
      "          -3.2579e-04, -1.4336e-03]]])\n",
      "tensor([[[ 4.1056e-03,  2.4565e-02,  4.4744e-02,  ..., -2.7622e-02,\n",
      "           3.3712e-02,  4.5050e-02]],\n",
      "\n",
      "        [[-8.5549e-03, -1.0698e-02, -1.6655e-03,  ...,  4.0021e-01,\n",
      "           3.8338e-01,  4.6705e-01]],\n",
      "\n",
      "        [[ 1.4147e-02,  3.1701e-02,  3.5567e-02,  ...,  1.2663e-01,\n",
      "           1.2048e-01,  1.2608e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.0860e-03, -1.7457e-02, -2.9115e-02,  ...,  4.4236e-04,\n",
      "           1.0782e-03,  9.0665e-04]],\n",
      "\n",
      "        [[-7.3640e-02, -1.2632e-01, -1.1043e-01,  ..., -2.6970e-02,\n",
      "          -2.3401e-02, -2.4147e-02]],\n",
      "\n",
      "        [[-1.6425e-01, -2.8360e-01, -2.6193e-01,  ..., -1.5926e-01,\n",
      "          -7.7522e-02, -4.6627e-02]]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_201330/293834034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'TypeError'>, TypeError('an integer is required'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2082\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2083\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_pdb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                         \u001b[0;31m# drop into debugger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36m_showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;34m'traceback'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;34m'ename'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;34m'evalue'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         }\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda/envs/defensemae/lib/python3.8/site-packages/soundfile.py\u001b[0m in \u001b[0;36merror_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \u001b[0;34m\"\"\"Raw libsndfile error message.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             \u001b[0merr_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "for samples in data_loader_train:\n",
    "    print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 2304])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2, 512, 768)\n",
    "a.repeat(1, 1, 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Attention(768, 12, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 512, 768)\n",
    "mask = torch.zeros(2, 512, 768).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 512, 64])\n",
      "torch.Size([2, 12, 512, 64])\n",
      "torch.Size([2, 12, 512, 512])\n",
      "12\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (768) must match the size of tensor b (512) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74532/880154089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda/envs/audiomae/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apoman123/defensemae/model/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, padding_mask)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding_mask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (768) must match the size of tensor b (512) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "attention(a, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedAutoencoder(embed_dim=768, do_mask=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2843e-01,  ...,  1.0000e+00,\n",
       "          1.0243e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.2799e-01,  ...,  1.0000e+00,\n",
       "          2.0486e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [-5.2150e-01,  8.5325e-01,  1.4631e-01,  ...,  9.9677e-01,\n",
       "          7.8379e-02,  9.9692e-01],\n",
       "        [ 4.3622e-01,  8.9984e-01,  9.0147e-01,  ...,  9.9676e-01,\n",
       "          7.8481e-02,  9.9692e-01],\n",
       "        [ 9.9288e-01,  1.1912e-01,  8.6351e-01,  ...,  9.9676e-01,\n",
       "          7.8583e-02,  9.9691e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder_pos_embed.position_encoding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(spec_batch, in_chanel, embed_dim, patch_size=16, smallest_length=1024):\n",
    "    # the default longest length of a spectrogram is 1024\n",
    "    padded_specs = torch.tensor([])\n",
    "    embeder = nn.Conv2d(in_chanel, embed_dim, kernel_size=(patch_size, patch_size), stride=(patch_size, patch_size), bias=False)\n",
    "    embeder.weight.requires_grad = False\n",
    "    N, C, H, W = spec_batch.shape\n",
    "    longest = smallest_length\n",
    "\n",
    "    # find the longest \n",
    "    for idx in range(N):\n",
    "        spec = spec_batch[idx, :, :, :]\n",
    "        spec_c, spec_h, spec_w = spec.shape\n",
    "        if spec_w > longest:\n",
    "            longest = spec_w\n",
    "\n",
    "    # pad the spectrogram\n",
    "    for idx in range(N):\n",
    "        spec = spec_batch[idx, :, :, :]\n",
    "        spec_c, spec_h, spec_w = spec.shape\n",
    "        if spec_w < longest:\n",
    "            pads = torch.zeros(spec_c, spec_h, longest - spec_w)\n",
    "            padded_spec = torch.cat([spec, pads], dim=-1).unsqueeze(0)\n",
    "            padded_specs = torch.cat([padded_specs, padded_spec], dim=0)\n",
    "\n",
    "    # get the padding mask\n",
    "    padding_masks = embeder(padded_specs).flatten(2).transpose(1, 2)\n",
    "    padding_masks = torch.where(padding_masks == 0, 1, 0).bool()\n",
    "\n",
    "    return padded_specs, padding_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 1, 128, 1001)\n",
    "a, masks = padding(a, 1, 768, 16, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 768])\n",
      "torch.Size([2, 512, 512])\n",
      "torch.Size([2, 512, 256])\n"
     ]
    }
   ],
   "source": [
    "print(masks.shape)\n",
    "print(masks[:, :, :512].shape)\n",
    "print(masks[:, :, :256].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 512, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.5013, 1.5960, 1.5284,  ..., 1.4298, 1.4465, 0.0000],\n",
       "         [1.5653, 1.5508, 1.5583,  ..., 1.5301, 1.4107, 0.0000]],\n",
       "        grad_fn=<MeanBackward1>),\n",
       " tensor([[[-0.1342, -1.7399,  2.5878,  ...,  1.4804,  1.3534,  1.0617],\n",
       "          [-0.1890, -1.7116,  2.8103,  ...,  1.5090,  1.4721,  1.0208],\n",
       "          [-0.2631, -1.5977,  3.0126,  ...,  1.5937,  1.0246,  1.2272],\n",
       "          ...,\n",
       "          [-0.1900, -2.7658,  2.5324,  ...,  0.8216,  0.5004,  1.2674],\n",
       "          [-0.0825, -2.7024,  2.5177,  ...,  0.8202,  0.5130,  1.2409],\n",
       "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.2108, -1.7987,  2.5642,  ...,  1.4829,  1.3316,  0.8886],\n",
       "          [-0.1336, -1.7770,  2.9069,  ...,  1.5689,  1.3558,  1.1317],\n",
       "          [-0.2668, -1.5569,  3.0893,  ...,  1.3738,  1.0580,  1.2533],\n",
       "          ...,\n",
       "          [-0.1837, -2.8484,  2.5315,  ...,  0.7940,  0.5916,  1.2866],\n",
       "          [-0.0241, -2.7930,  2.5626,  ...,  0.8455,  0.5201,  1.2673],\n",
       "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([0.], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a, padding_mask=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(imgs):\n",
    "    h = imgs.shape[2] // 16\n",
    "    w = imgs.shape[3] // 16\n",
    "    x = imgs.reshape(shape=(imgs.shape[0], 1, h, 16, w, 16))\n",
    "    x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "    x = x.reshape(shape=(imgs.shape[0], h * w, 16**2 * 1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = patchify(torch.rand(2, 1, 128, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(audiomae)",
   "language": "python",
   "name": "audiomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
